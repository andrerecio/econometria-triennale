---
title: "Esercitazione N.7-8"
author: "Econometria"
format: 
  html:
    toc: true
    code-fold: false
    embed-resources: true
execute:
  warning: false
  message: false
---


# Regressione con variabili strumentali

In questa Esercitazione vedremo le regressioni con variabili strumentali (IV) per risolvere il problema dell'endogeneit√† di una o pi√π variabili esplanatorie.


Tre importanti minacce alla validit√† interna sono:

1. Distorsione da variabili omesse per una variabile correlata con $X$ ma inosservata (perci√≤ non pu√≤ essere inclusa nella regressione) e per cui vi sono variabili di controllo inadeguate;

2. Distorsione da causalit√† simultanea ($X$ causa $Y$ , $Y$ causa $X$);

3. Distorsione da errori nelle variabili ($X$ √® misurata con errore)


Tutti e tre i problemi comportano $ùê∏(u_i | X_i) \neq 0$. La regressione con variabili strumentali pu√≤ eliminare la distorsione quando $ùê∏(u_i | X_i) \neq 0$ -usando una variabile strumentale (IV), $Z$.

**Idea chiave:**

Lo stimatore IV con un singolo regressore e un singolo strumento $Y_i = \beta_0 + \beta_1 X_i + u_i$

- La regressione IV divide $X$ in due parti: una che potrebbe essere correlata con $u$, e una che non lo √®.
Isolando la parte che non √® correlata con $u_i$, √® possibile stimare $\beta_1$.

- Per fare questo si utilizza una variabile strumentale, $Z_i$, che √® correlata con $X_i$ ma non correlata con $u_i$


Perch√© una variabile strumentale (uno ‚Äústrumento‚Äù) $Z$ sia valida, deve soddisfare due condizioni:

1. **Rilevanza:** $cor(Z_i, X_i) \neq 0$
2. **Esogeneit√†:** $cor(Z_i, u_i) = 0$

**Pacchetti necessari:**

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(knitr)
library(kableExtra)
library(modelsummary)
library(fixest)
library(wooldridge)
```


## Card (1995)

Card (1995) ha utilizzato dati su salari e istruzione relativi ad un campione di uomini nel 1976 per stimare il rendimento dell‚Äôistruzione.

Egli ha impiegato una variabile dummy che indica se un individuo √® cresciuto vicino a un college quadriennale ($nearc4$) come strumento per l‚Äôistruzione.

Card ha cercato di risolvere questo problema utilizzando la distanza di ciascuno studente dal college pi√π vicino come variabile strumentale. L'ipotesi alla base di questo √® che una minore distanza geografica dal college riduca il "costo" di frequentare l'universit√† e quindi aumenti la probabilit√† di iscriversi. Allo stesso tempo, la distanza dal college non dovrebbe essere direttamente collegata alla variabile di interesse, ovvero "i salari futuri".



Pertanto, se $nearc4$ √® realmente incorrelato con i fattori non osservabili inclusi nel termine d‚Äôerrore, pu√≤ essere utilizzato come strumento per $educ$.


```{r}
data("card", package = "wooldridge")
head(card)
```


- $wage$: sono le retribuzioni orarie **in centesimi** di dollari
- $educ$: sono gli anni di istruzione
- $exper$: anni di esperienza 
- $smsa$: residenza in area metropolitana (dummy)
- $black$: se la persona √® nera (dummy)
- $south$: se l'individuo risiede al sud
- $nearc4$: dummy uguale ad 1 se l'individuo vive vicino a un college di 4 anni
- $nearc2$: dummy uguale ad 1 se l'individuo vive vicino a un college di 2 anni
  

**Esercizio:**

```{r}
wage_educ <- feols(wage ~ educ + exper, data = card, vcov = "hetero")
logwage_educ <- feols(log(wage) ~ educ + exper, data = card, vcov = "hetero")


modelsummary(
  list("Wage" = wage_educ, "Log Wage" = logwage_educ),
  output = "markdown", gof_omit = "AIC|BIC|RMSE|R2 Adj."
)
```

::: {.callout-note title="Domande"}
1. Come si interpretano i coefficienti di $educ$ nelle due regressioni?
2. Se $wage$ fosse espresso in dollari (e non centinaia di dollari) cosa cambierebbe nelle due regressioni? 
:::



### Minimi quadrati in due stadi (TSLS)

```{r}
iv_card <- feols(log(wage) ~ 1 | educ ~ nearc4, data = card, vcov = "hetero")
iv_card
```


La regressione IV usando `feols` si stima `log(wage) ~ 1 | educ ~ nearc4`



Il metodo del two stage least squares (TSLS), √® equivalente ad usare i valori predetti del primo stadio nel secondo stadio (gli errori standard sono sbagliati perch√© non tengono conto della stima nel primo stadio). Come sempre usiamo errori standard robusti all'eteroschedasticit√†.


```{r}
fs_card <- feols(educ ~ nearc4, data = card, vcov = "hetero")
fs_card

card$educ_hat <- predict(fs_card)
```


Regressione "manuale" dei valori predetti di $educ$:

```{r}
sstage_card <- feols(log(wage) ~ educ_hat, data = card, vcov = "hetero")
sstage_card
```


### Derivazione algebrica diretta

In questo caso il coefficiente $\beta_1$ √® equivalente al rapporto tra la covarianza campionaria di $Z$ e $Y$ e la covarianza campionaria di $Z$ e $X$.


```{r}
cov(card$nearc4, card$lwage)/cov(card$nearc4, card$educ)
```


### Derivazione dalla "Forma Ridotta"

$$
Y_i = \beta_0 + \beta_1 X_i + u_i
$$

$$
X_i = \pi_0 + \pi_1 Z_i + v_i
$$

Sostituendo $X_i$ in $Y_i$ otteniamo:

$$
Y_i = \gamma_0 + \gamma_1 Z_i + \omega_i
$$

La regressione dell'endogena sullo strumento l'abbiamo stimata in precedenza `fs_card`. Ora stimiamo la regressione della variabile dipendente sullo strumento. 

```{r}
rf_card <- feols(log(wage) ~ nearc4, data = card, vcov = "hetero")
rf_card
```

E dividiamo i coefficienti:
$$
\hat{\beta}^{TSLS} = \frac{\hat{\gamma_1}}{\hat{\pi_1}}
$$

```{r}
# Estrai i coefficienti
beta_fs_1 <- coef(fs_card)["nearc4"]  # coefficiente del primo stadio
beta_rf_1 <- coef(rf_card)["nearc4"]  # coefficiente della forma ridotta

beta_rf_1 / beta_fs_1  

```


### Modello generale

```{r}
iv_card_controlli <- feols(log(wage) ~ exper + black + smsa + south + married | educ ~ nearc4, data = card, vcov = "hetero")

summary(iv_card_controlli)

```


**Confronto OLS:**

```{r}
ols_card_controlli <- feols(log(wage) ~ exper + black +smsa + south + educ + married, data = card, vcov = "hetero")

modelsummary(
  list("Log Wage (OLS)" = ols_card_controlli, "Log Wage (IV)" = iv_card_controlli),
  output = "markdown", gof_omit = "AIC|BIC|RMSE|R2 Adj."
)

```


Nella regressione OLS, un anno aggiuntivo di istruzione √® associato a un incremento, in media, di $wage$ di circa il 7,1%, a parit√† delle altre variabili.

La regressione TSLS riporta un valore pi√π alto: un anno un anno aggiuntivo di istruzione √® associato a un incremento, in media, di $wage$ di circa il 12.4%.


### Sovraidentificazione e strumenti deboli

```{r}
iv_card_overid <- feols(log(wage) ~ exper + black +smsa + south + married | educ ~ nearc4 + nearc2, data = card, vcov = "hetero")
iv_card_overid
```



**Test restrizioni di sovraidentificazione:** Se gli strumenti sono correlati con il termine d‚Äôerrore, il primo stadio del TSLS non pu√≤ isolare una componente di $X$ incorrelata con il termine d‚Äôerrore, perci√≤ ÃÇ$X$ √® correlata con $u$ e il TSLS √® inconsistente.


Se ci sono pi√π strumenti che regressori endogeni, √® possibile verificare -**parzialmente** - l‚Äôesogeneit√† dello strumento.

Possiamo eseguire una verifica parziale di esogeneit√†: se $m > 1$, possiamo verificare l‚Äôipotesi nulla che tutti gli strumenti siano esogeni contro l‚Äôalternativa che al massimo $m-1$ siano endogeni (correlati con $u$)

- Si usa il test $J$, realizzato usando i residui TSLS.

- Se il $J$ respinge l‚Äôipotesi, allora almeno alcuni degli strumenti sono endogeni, perci√≤ occorre prendere una decisione difficile e scartare alcuni (o tutti) gli strumenti


- $H_0$ :strumenti¬†esogeni, cio√® non correlati con il termine d‚Äôerrore.
- $H_1$: almeno uno degli strumenti √® endogeno.

Se p-value > 0.05 allora **non** rigettiamo $H_0$

Il libro (Stock e Watson pp. 344-345 o pp. 448-449 in inglese) deriva una versione valida sotto omoschedasticit√†:

1. Stimiano la regressione TSLS
2. Si ottengono i residui della regressione TSLS:  
   $\hat{u}_i = Y_i - \hat{Y}_i$
3. Si esegue una regressione dei residui $\hat{u}_i$ sugli strumenti $Z_1, \dots, Z_m$ e le variabili esogene $W_1, \dots, W_r$
4. Se gli strumenti fossero esogeni i coefficienti degli strumenti nella regressione di $\hat{u}_i$ dovrebbero essere uguali a zero (statisticamente non significativi)
5. Si calcola come $J = mF$. Quindi $J = Wald$
6. In grandi campioni si distribuisce come una chi-quadrato con $m-k$ gradi di libert√† ($\chi_{m-k}$)

$m-k$ √® il grado di sovraidentificazione ($k$ sono i regressori endogeni)


```{r}
library(car)
card <- card |> mutate(uhat = log(wage) - iv_card_overid$fitted.values)
Jlm <- feols(uhat~ nearc4 + nearc2 + exper + black +smsa + south + married, data = card, vcov = "iid")
J <- linearHypothesis(Jlm, c("nearc4=0", "nearc2=0"))
J
```

Qui rifiuto l'ipotesi nulla, almeo uno dei due strumenti √® endogeno


**Weak instrument:** Se la statistica Wald del primo stadio √® minore di $m \times 10$, allora l‚Äôinsieme degli strumenti √® debole.

```{r}
linearHypothesis(fs_card , "nearc4=0")
```

```{r}
linearHypothesis(fs_card , "nearc4=0", test="F")
```

**2 strumenti**:

```{r}
fs_card_overid <- feols(educ ~ nearc4 + nearc2 + exper + black +smsa + south + married, data = card, vcov = "hetero")

linearHypothesis(fs_card_overid, c("nearc4=0", "nearc2=0"))
```


## Angrist and Evans (1998)

In *Children and Their Parents' Labor Supply: Evidence from Exogenous Variation in Family Size*, pubblicato su *American Economic Review*, Angrist e Evans analizzano l‚Äôeffetto della presenza di figli sull‚Äôofferta di lavoro dei genitori (misurata in termini di ore lavorate settimanali).

Per superare il problema di endogeneit√† nella decisione di avere figli ‚Äî dovuto alla possibile correlazione con altri determinanti dell‚Äôofferta di lavoro ‚Äî Angrist ed Evans si concentrano sui genitori con almeno due figli e utilizzano come variabile strumentale se i primi due figli sono dello stesso sesso ($samesex$) o se il secondo parto √® gemellare ($multi2nd$).

Rilevanza? Le famiglie i cui primi due figli sono entrambi maschi (o entrambe femmine) hanno (avevano) pi√π probabilit√† di avere un terzo figlio.

Esogeneit√†? La composizione di genere dei figli NON dovrebbe influenzare direttamente l‚Äôofferta di lavoro della madre.

Nel dataset `labsup` √® contenuta una parte dei dati utilizzati da Angrist ed Evans (1998).


```{r}
data("labsup", package = "wooldridge")
head(labsup)
```

```{r}
# Modello IV (samesex come strumento per kids)
iv_labsup <- feols(hours ~ educ + age + black + hispan | kids ~ samesex, data = labsup, vcov = "hetero")
```


Primo stadio:
```{r}
summary(iv_labsup, stage =1)
```

Secondo stadio:
```{r}
summary(iv_labsup, stage =2)
```

Confronto con stima OLS.

```{r}
#OLS ore e numero figli
ols_labsup <- feols(hours ~ kids + educ + age + black + hispan, data = labsup, vcov = "hetero")

modelsummary(
  list("OLS" = ols_labsup,
       "IV" = iv_labsup),
  stars = TRUE,
  gof_omit = "IC|Adj|RMSE"
)
```


::: {.callout-note title="Domanda"}
1. Come si interpretano i coefficienti di $educ$ e $kids$ nella regressione OLS? 
:::


Un altro possibile strumento √® $multi2nd$ che assume valore 1 se il secondo parto √® gemellare:

- Avere un parto gemellare aumenta la dimensione familiare (Rilevanza)

- Esogeneit√†? Avere gemelli al secondo parto non dovrebbe influenzare direttamente l‚Äôofferta di lavoro della madre

```{r}
iv_labsup_twins <- feols(hours ~ educ + age + black + hispan | kids ~ multi2nd, data = labsup, vcov = "hetero")
```

Primo stadio:
```{r}
summary(iv_labsup_twins, stage =1)
```

Secondo stadio:
```{r}
summary(iv_labsup_twins, stage =2)
```


**Confronto:**

```{r}
modelsummary(
  list("Hours (IV samesex)" = iv_labsup ,
       "Hours (IV multi2nd)" = iv_labsup_twins),
  stars = TRUE,
  gof_omit = "IC|Adj|RMSE"
)
```

### Sovraidentificazione

```{r}
iv_labsup_twins_over <- feols(hours ~ educ + age + black + hispan | kids ~ multi2nd + samesex, data = labsup, vcov = "hetero")
iv_labsup_twins_over
```

::: {.callout-note title="Domande"}
1. Provate a calcolare Wald del primo stadio sugli strumenti e fate il test delle restrizioni da sovraidentificazione
:::